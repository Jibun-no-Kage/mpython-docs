.. _constrained:

MicroPython in the microcontroller
===============================

MicroPython is designed to run on a microcontroller. Programmers familiar with conventional computers may not be familiar with these hardware limitations.
Especially RAM and non-volatile "disk"（flash memory）storage capacity is limited. This tutorial provides a method to make full use of limited resources.
Since MicroPython runs on controllers based on various architectures, the method provided is universal：In some cases,
Need to get detailed information from platform specific documentation.

Flash memory
------------

On Pyboard, the simple way to solve the limited capacity is to install a micro SD card. But sometimes because the device does not have an SD card slot or for cost or power consumption reasons,
This method is not feasible；Therefore, on-chip flash memory must be used. Firmware containing MicroPython subsystem is stored in onboard flash. Available capacity.
Due to reasons related to the physical structure of flash memory, part of this capacity may not be accessible as a file system. Under these circumstances，
This space can be used by incorporating the user module into the firmware version that is subsequently flashed into the device.

There are two ways to achieve this：Freeze module and freeze bytecode. Freeze module stores Python source code with firmware.
Freezing bytecode uses a cross-compiler to convert source code to bytecode that is then stored with the firmware. The import statement can be used to access the module in both cases:

.. code::

    import mymodule

The process of generating frozen modules and bytecode depends on the platform；For instructions on building firmware, please refer to the README file in the relevant section of the source code tree。

In general, the steps are as follows:

* Clone the MicroPython `repository <https://github.com/micropython/micropython>`_.
* Obtain (platform specific) toolchain to build firmware.
* Build cross compiler.
* Place the module to be frozen in the specified directory (depends on freezing the module as source/bytecode).
* Build firmware. Need specific instructions to build any type of freeze code-see platform documentation.
* Flash the firmware to the device.

RAM
---

There are two stages to consider when reducing RAM usage：Compile and Execute. In addition to memory consumption, there is also a problem called heap fragmentation. In general, it is best to minimize repeated creation and damage of objects.
The reason is described in the section related to heap（ `heap`_）.

Compile stage
~~~~~~~~~~~~~~~~~

When importing the module, MicroPython compiles the code into bytecode, and then the MicroPython virtual machine (VM) executes the bytecode.
The bytecode is stored in RAM. The compiler itself requires RAM, but it is only available after compilation.

If multiple modules have been imported, this will happen when there is not enough RAM to run the compiler. In this case, the import statement will raise a memory exception.

If the module instantiates a global object during import, RAM will be occupied during import and the compiler cannot use the RAM in subsequent imports. Usually,
It is best to avoid code that runs on import； A better way is to have the initialization code run by the application after all modules are imported.
This method maximizes the RAM available to the compiler.

If RAM is still not enough to compile all modules, one solution is to pre-compile the modules. MicroPython has a cross compiler，
Python modules can be compiled into bytecode (see README in the mpy-cross directory). The extension of the generated bytecode file is  .mpy.
This file may be copied to the file system and imported in the usual way. Alternatively, some or all modules can be implemented as frozen bytecode：
On most platforms, this saves more RAM because the bytecode runs directly from the flash memory and is not stored in the RAM.

Execution phase
~~~~~~~~~~~~~~~

There are many coding techniques that can reduce the use of RAM.

**Constant**

MicroPython provides the ``const`` keyword that can be used as follows:

.. code::

    from micropython import const
    ROWS = const(33)
    _COLS = const(0x10)
    a = ROWS
    b = _COLS

In both cases where a constant is assigned to a variable, the compiler will avoid encoding the lookup as a constant name by replacing its constant value. This saves bytecode, 
Which also saves RAM. But the ``ROWS`` value will occupy at least two machine words, which correspond to the key value and value in the globals dictionary.
Must appear in the dictionary because another module may import or use it. This RAM can be saved by putting an underscore in front of the name (such as  ``_COLS`` ).
This RAM can be saved by using underscore as the name of in_COLS：This symbol is not visible outside the module, so it will not occupy RAM.

The parameter of ``const()`` can be any value calculated as an integer at compile time, such as  ``0x100`` or ``1 << 8`` .
It can even include other defined constant symbols, such as ``1 << BIT`` 。

**Constant Data Structure**

If there is a large amount of constant data, and the platform supports execution from Flash, the RAM may be saved as follows. Data should be in Python module and frozen as bytecode.
Data must be defined as `bytes` object. The compiler "know" that the `bytes`  object is immutable, and ensures that the object remains in flash memory, not being copied into RAM.
`ustruct` module assists in the conversion between types and other Python built-in types.

When considering the meaning of frozen bytecode, please note：In Python, strings, floating-point numbers, bytes, integers, and complex numbers are immutable. So these will be frozen into Flash. Therefore, in the following line

.. code::

    mystring = "The quick brown fox"

The actual string "The quick brown fox" will stay in Flash. At runtime, the string reference is assigned to the variable  ``mystring`` .
The quote occupies a machine word. In principle, long integers can be used to store constant data:

.. code::

    bar = 0xDEADBEEF0000DEADBEEF

As shown in the string example, at runtime, a reference to an arbitrary large integer is assigned to the variable bar. The reference occupies one machine byte.

It is expected that integer tuples can be used to store constant data with minimal RAM space. In the case of using the current compiler, this is invalid (code works, but RAM is not saved).

.. code::

    foo = (1, 2, 3, 4, 5, 6, 100000)

The runtime tuple will be located in RAM. This may be improved in the future.

**No need to create objects**

很多情况下，可能无意地创建和销毁了对象。这可能会因碎片化而降低RAM的可用性。以下部分讨论此类实例。

**字串连接**

思考下面的代码段，其目的是产生常量字符串:

.. code::

    var = "foo" + "bar"
    var1 = "foo" "bar"
    var2 = """\
    foo\
    bar"""

每个代码段都产生相同结果，但是第一个代码在运行时却创建了两个不必要的字符串对象，并在生成第三个对象前为连接分配更多的RAM。
其他编译器在编译时执行更高效的连接，从而降低碎片化。

在字符串输入流（如文件）之前须动态创建字符串的情况下，若以零碎方式完成，则会节省RAM。
创建一个子字符串（而不是创建一个大型字符串对象），并在处理下一个字符串前将其输入到流中。

创建动态字符串的最佳方式是通过字符串 `format` 方法:

.. code::

    var = "Temperature {:5.2f} Pressure {:06d}\n".format(temp, press)

**缓冲区**

当访问诸如UART、I2C和SPI接口的设备时，使用预分配的缓冲器避免不要的对象创建。思考这两个循环:

.. code::

    while True:
        var = spi.read(100)
        # process data 处理数据

    buf = bytearray(100)
    while True:
        spi.readinto(buf)
        # process data in buf 在缓冲区中处理对象

第一个循环在每次传递时创建一个缓冲区，第二个循环则重新使用一个预分配的缓冲区；这在内存碎片化方面既快又有效。

**字节小于整数**

在大多数平台中，一个整数消耗四个字节。思考这两个函数 ``foo()`` 的调用:

.. code::

    def foo(bar):
        for x in bar:
            print(x)
    foo((1, 2, 0xff))
    foo(b'\1\2\xff')

首次调用中，在RAM中创建一个整数元组。第二次调用有效地创建消耗最小RAM的 ``bytes`` 对象。
若模块被冻结为字节码，则 ``bytes`` 对象将保留在Flash中。

**字符串vs字节**

Python3引入了Unicode支持，也就引入了字符串和字节数组之间的区别。只要字符串中的所有字符都为ASCII（即值<126），
MicroPython即可确保Unicode字符串不占用额外空间。若需完整8位范围内的值，则可使用 `bytes` 和 `bytearray` 对象来确保无需额外空间。
请注意：大多数字符串方法（例如 :meth:`str.strip()`）也适用于 `bytes` 实例，所以消除Unicode并不困难。

.. code::

    s = 'the quick brown fox'   # A string instance 一个字符串实例
    b = b'the quick brown fox'  # A bytes instance 一个字节实例

在需在字符串和字节之间进行转换之处，可使用 `str.encode()` 和 `bytes.decode()` 方法。请注意：字符串和字节都是不可变的。
任何将这种对象作为输入并产生另一个对象的操作都表示，为产生结果，至少有一次RAM分配。在下面第二行中，分配了一个新的字节对象。
若 ``foo`` 为字符串，也会出现这种情况。

.. code::

    foo = b'   empty whitespace'
    foo = foo.lstrip()

**运行时的编译器执行**

Python的函数 `eval` 和 `exec` 在运行时调用编译器，这需要大量的RAM。请注意：来自 `micropython-lib` 的
`pickle` 库使用 `exec` 。使用 `ujson` 库进行对象序列化可能会更高效地利用RAM。

**将字符串储存到Flash中**

Python字符串是不可变的，因此可能存储在只读存储器中。编译器可将Python代码中定义的字符串置于Flash中。
与冻结模块一样，必须在PC上有一个源代码树的副本，然后使用工具链来构建固件。即使模块尚未完全调试，只要可以导入并运行，该程序仍将正常工作。

导入模块后，执行:

.. code::

    micropython.qstr_info(1)

然后将所有Q(xxx)行复制并粘贴到文本编辑器中。检查并删除明显无效的行。 打开将在stmhal中（或使用中的架构的等效目录）
的文件qstrdefsport.h。将更正的行复制并粘贴到文件末尾。保存文件，重建并刷新固件。可通过导入模块和再次发出来检查结果:

.. code::

    micropython.qstr_info(1)

Q(xxx) 行应消失。

.. _heap:

堆
--------

当正在运行的程序实例化对象时，将从一个固定大小的池中分配必要的RAM，这个池被称为堆。当对象超出范围
（换言之：已不可用于代码）时，冗余对象即为"垃圾"。"垃圾回收"（GC）的进程回收该内存，并将其返回到空闲堆。
这个过程自动进行，但可通过发出 `gc.collect()` 来直接调用。

有关这方面的讨论有所涉及。为"快速修复"，定期发布以下内容:

.. code::

    gc.collect()
    gc.threshold(gc.mem_free() // 4 + gc.mem_alloc())

碎片化
~~~~~~~~~~~~~

程序创建对象 ``foo`` ，然后创建对象 ``bar`` 。随后 ``foo`` 超出范围，但 ``bar`` 仍保留。 ``foo`` 所占用的
RAM将被GC回收。但是，若 ``bar`` 被分配到更高地址，从 ``foo`` 回收的RAM只能用于不大于 ``foo`` 的对象。
在复杂或长时间运行的程序中，堆可进行碎片化处理：尽管存在大量可用的RAM，但并无足够的连续空间来分配特定对象，且程序因存储器错误而失效。

上述技术旨在最大限度地减少这种情况。 在需要大的永久性缓冲区或其他对象的情况下，最好在程序执行过程中、
碎片化进行前尽早将这些缓冲区实例化。 可通过监视堆的状态和控制GC来进一步改进。概述如下。

报告
~~~~~~~~~

许多库函数可用于报告内存分配和控制GC。这些都可以在 `gc` 和 `micropython` 模块中找到。
下面的例子可能被粘贴在REPL（ctrl e进入粘贴模式，ctrl d运行它）。许多库函数可用于报告内存分配并控制GC。
这些同样存在 `gc` 和 `micropython` 模块中。以下示例可能粘贴到REPL中（ ``ctrl e`` 进入粘贴模式， ``ctrl d`` 运行它）。

.. code::

    import gc
    import micropython
    gc.collect()
    micropython.mem_info()
    print('-----------------------------')
    print('Initial free: {} allocated: {}'.format(gc.mem_free(), gc.mem_alloc()))
    def func():
        a = bytearray(10000)
    gc.collect()
    print('Func definition: {} allocated: {}'.format(gc.mem_free(), gc.mem_alloc()))
    func()
    print('Func run free: {} allocated: {}'.format(gc.mem_free(), gc.mem_alloc()))
    gc.collect()
    print('Garbage collect free: {} allocated: {}'.format(gc.mem_free(), gc.mem_alloc()))
    print('-----------------------------')
    micropython.mem_info(1)

以上使用的方法:

* `gc.collect()` 强制执行垃圾收集。见脚注。
* `micropython.mem_info()` 打印RAM利用率的总结。
* `gc.mem_free()` 返回空闲堆大小（以字节为单位）。
* `gc.mem_alloc()` 返回当前分配的字节数量。
* ``micropython.mem_info(1)`` 打印堆利用率的表格（详情见下）。

生成的数字取决于平台，但可以看到，定义函数使用由编译器发出的字节码形式的少量RAM（编译器使用的RAM已被回收）。
运行该函数使用超过10KiB，但返回时， ``a`` 为垃圾，因为它超出范围且无法引用。最后的 `gc.collect()` 会恢复内存。

由 ``micropython.mem_info(1)`` 生成的最终输出将有所不同，但可能会如下解释:

====== =================
 符号    含义
   .   空闲块
   h   head block
   =   tail block
   m   marked head block
   T   元组
   L   列表
   D   字典
   F   浮点数
   B   字节代码
   M   模块
====== =================

每个字母代表一个内存块，每个块16字节。因此，堆转储的一行代表0x400字节或1KiB的RAM。

控制垃圾回收
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

可随时通过发出 `gc.collect()` 来请求GC。定期执行首先有助于防止碎片化，其次也有利于提高性能。
GC可能耗费数毫秒，在工作量较小时耗时更短（在Pyboard上只需大约1ms）。显式调用可最大限度减少延迟，
同时确保其在程序中可接受的情况下出现。

以下情况下，自动GC将被激活。尝试分配失败时，执行GC并重新尝试分配。只有在此分配失败时才会引发异常。
其次，若可用RAM数量低于阈值，则会触发自动GC。这个阈值可随执行进行而调整:

.. code::

    gc.collect()
    gc.threshold(gc.mem_free() // 4 + gc.mem_alloc())

超过25％的当前空闲堆被占用时，将触发GC。

通常，模块应在运行时使用构造函数或其他初始化函数实例化数据对象。这一因为，若在初始化时发生这种情况，
则在导入后续模块时，编译器可能会缺乏可用RAM。若模块在导入时实例化数据，那么在导入后发出的 `gc.collect()` 会改善这一问题。

字符串操作
-----------------

MicroPython以有效的方式处理字符串，理解其处理方式这可帮助设计在微控制器上运行的应用程序。
模块被编译时，出现多次的字符串只存储一次，此过程被称为字符串驻留。在MicroPython中，
驻留字符串被称为 ``qstr`` 。在正常导入的模块中，单个实例将位于RAM中，但如上所述，在冻结为字节码的模块中，则将位于Flash中。

字符串对比也使用散列有效进行（而非逐个字符执行）。因此，在性能和RAM使用方面，使用字符串而非整数的惩罚可能会很小-这可能会让C程序员感到意外。

附言
----------

MicroPython传输、返回并（默认为）通过引用复制对象。一个引用占用一个机器字，所以这些进程在RAM使用率和速度方面较为高效。

在必需变量（其大小既非一个字节也非一个机器字）的情况下，将有可帮助有效存储变量并进行转换的标准库。
见 `array` 、 `ustruct` 和 `uctypes` 模块。

脚注：gc.collect()返回值
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

在Unix和Windows平台上， `gc.collect()` 方法返回一个整数，该整数表示在回收中收回的不同内存
区域的数量（更确切地说，是变为空闲块的head block的数量）。出于效率原因，baremetal端口不返回此值。
