.. _constrained:

MicroPython in the microcontroller
===============================

MicroPython is designed to run on a microcontroller. Programmers familiar with conventional computers may not be familiar with these hardware limitations.
Especially RAM and non-volatile "disk"（flash memory）storage capacity is limited. This tutorial provides a method to make full use of limited resources.
Since MicroPython runs on controllers based on various architectures, the method provided is universal：In some cases,
Need to get detailed information from platform specific documentation.

Flash memory
------------

On Pyboard, the simple way to solve the limited capacity is to install a micro SD card. But sometimes because the device does not have an SD card slot or for cost or power consumption reasons,
This method is not feasible；Therefore, on-chip flash memory must be used. Firmware containing MicroPython subsystem is stored in onboard flash. Available capacity.
Due to reasons related to the physical structure of flash memory, part of this capacity may not be accessible as a file system. Under these circumstances，
This space can be used by incorporating the user module into the firmware version that is subsequently flashed into the device.

There are two ways to achieve this：Freeze module and freeze bytecode. Freeze module stores Python source code with firmware.
Freezing bytecode uses a cross-compiler to convert source code to bytecode that is then stored with the firmware. The import statement can be used to access the module in both cases:

.. code::

    import mymodule

The process of generating frozen modules and bytecode depends on the platform；For instructions on building firmware, please refer to the README file in the relevant section of the source code tree。

In general, the steps are as follows:

* Clone the MicroPython `repository <https://github.com/micropython/micropython>`_.
* Obtain (platform specific) toolchain to build firmware.
* Build cross compiler.
* Place the module to be frozen in the specified directory (depends on freezing the module as source/bytecode).
* Build firmware. Need specific instructions to build any type of freeze code-see platform documentation.
* Flash the firmware to the device.

RAM
---

There are two stages to consider when reducing RAM usage：Compile and Execute. In addition to memory consumption, there is also a problem called heap fragmentation. In general, it is best to minimize repeated creation and damage of objects.
The reason is described in the section related to heap（ `heap`_）.

Compile stage
~~~~~~~~~~~~~~~~~

When importing the module, MicroPython compiles the code into bytecode, and then the MicroPython virtual machine (VM) executes the bytecode.
The bytecode is stored in RAM. The compiler itself requires RAM, but it is only available after compilation.

If multiple modules have been imported, this will happen when there is not enough RAM to run the compiler. In this case, the import statement will raise a memory exception.

If the module instantiates a global object during import, RAM will be occupied during import and the compiler cannot use the RAM in subsequent imports. Usually,
It is best to avoid code that runs on import； A better way is to have the initialization code run by the application after all modules are imported.
This method maximizes the RAM available to the compiler.

If RAM is still not enough to compile all modules, one solution is to pre-compile the modules. MicroPython has a cross compiler，
Python modules can be compiled into bytecode (see README in the mpy-cross directory). The extension of the generated bytecode file is  .mpy.
This file may be copied to the file system and imported in the usual way. Alternatively, some or all modules can be implemented as frozen bytecode：
On most platforms, this saves more RAM because the bytecode runs directly from the flash memory and is not stored in the RAM.

Execution phase
~~~~~~~~~~~~~~~

There are many coding techniques that can reduce the use of RAM.

**Constant**

MicroPython provides the ``const`` keyword that can be used as follows:

.. code::

    from micropython import const
    ROWS = const(33)
    _COLS = const(0x10)
    a = ROWS
    b = _COLS

In both cases where a constant is assigned to a variable, the compiler will avoid encoding the lookup as a constant name by replacing its constant value. This saves bytecode, 
Which also saves RAM. But the ``ROWS`` value will occupy at least two machine words, which correspond to the key value and value in the globals dictionary.
Must appear in the dictionary because another module may import or use it. This RAM can be saved by putting an underscore in front of the name (such as  ``_COLS`` ).
This RAM can be saved by using underscore as the name of in_COLS：This symbol is not visible outside the module, so it will not occupy RAM.

The parameter of ``const()`` can be any value calculated as an integer at compile time, such as  ``0x100`` or ``1 << 8`` .
It can even include other defined constant symbols, such as ``1 << BIT`` 。

**Constant Data Structure**

If there is a large amount of constant data, and the platform supports execution from Flash, the RAM may be saved as follows. Data should be in Python module and frozen as bytecode.
Data must be defined as `bytes` object. The compiler "know" that the `bytes`  object is immutable, and ensures that the object remains in flash memory, not being copied into RAM.
`ustruct` module assists in the conversion between types and other Python built-in types.

When considering the meaning of frozen bytecode, please note：In Python, strings, floating-point numbers, bytes, integers, and complex numbers are immutable. So these will be frozen into Flash. Therefore, in the following line

.. code::

    mystring = "The quick brown fox"

The actual string "The quick brown fox" will stay in Flash. At runtime, the string reference is assigned to the variable  ``mystring`` .
The quote occupies a machine word. In principle, long integers can be used to store constant data:

.. code::

    bar = 0xDEADBEEF0000DEADBEEF

As shown in the string example, at runtime, a reference to an arbitrary large integer is assigned to the variable bar. The reference occupies one machine byte.

It is expected that integer tuples can be used to store constant data with minimal RAM space. In the case of using the current compiler, this is invalid (code works, but RAM is not saved).

.. code::

    foo = (1, 2, 3, 4, 5, 6, 100000)

The runtime tuple will be located in RAM. This may be improved in the future.

**No need to create objects**

In many cases, objects may be created and destroyed unintentionally. This may reduce RAM availability due to fragmentation. The following section discusses such examples.

**String Connection**

Consider the following code snippet, whose purpose is to generate a constant string:

.. code::

    var = "foo" + "bar"
    var1 = "foo" "bar"
    var2 = """\
    foo\
    bar"""

Each code segment produces the same result, but the first code creates two unnecessary string objects at runtime and allocates more RAM for the connection before generating the third object.
Other compilers perform more efficient linking at compile time, thereby reducing fragmentation.

In the case where a character string must be dynamically created before the string input stream (such as a file), if it is completed in a piecemeal manner, RAM will be saved.
Create a substring (instead of creating a large string object) and enter it into the stream before processing the next string.

The best way to create dynamic strings is through the string `format` method:

.. code::

    var = "Temperature {:5.2f} Pressure {:06d}\n".format(temp, press)

**Buffer Zone**

When accessing devices such as UART, I2C, and SPI interfaces, use pre-allocated buffers to avoid unwanted object creation. Consider these two loops:

.. code::

    while True:
        var = spi.read(100)
        # process data 

    buf = bytearray(100)
    while True:
        spi.readinto(buf)
        # process data in buf 

The first loop creates a buffer on each pass, and the second loop reuses a pre-allocated buffer；This is both fast and effective in terms of memory fragmentation.

**Byte less than integer**

On most platforms, an integer consumes four bytes. Consider the call of these two functions ``foo()`` :

.. code::

    def foo(bar):
        for x in bar:
            print(x)
    foo((1, 2, 0xff))
    foo(b'\1\2\xff')

In the first call, create an integer tuple in RAM. The second call effectively creates the  ``bytes`` object that consumes the least RAM.
If the module is frozen as bytecode, the ``bytes`` object will remain in Flash.

**String vs Bytes**

Python3 introduced Unicode support, which introduced the difference between strings and byte arrays. As long as all characters in the string are ASCII (ie value <126),
MicroPython ensures that Unicode strings do not take up extra space. If you need a full 8-bit value, you can use `bytes` and  `bytearray` objects to ensure that no extra space is required.
Please note: most string methods (e.g. :meth:`str.strip()`）also applies to `bytes` instances, so eliminating Unicode is not difficult. 

.. code::

    s = 'the quick brown fox'   # A string instance 
    b = b'the quick brown fox'  # A bytes instance 

Where you need to convert between strings and bytes, you can use the `str.encode()` and `bytes.decode()` method. Please note: strings and bytes are immutable.
Any operation that takes this object as input and produces another object means that to produce the result, there is at least one RAM allocation. In the second line below, a new byte object is allocated.
This will also happen if ``foo`` is a string.

.. code::

    foo = b'   empty whitespace'
    foo = foo.lstrip()

**Compiler Execution at Runtime**

Python functions `eval` and `exec` call the compiler at runtime, which requires a lot of RAM. Please note: from `micropython-lib`  
`pickle` library uses `exec` . Object serialization using the `ujson` library may make more efficient use of RAM.

**Store the String in Flash**

Python strings are immutable, so they may be stored in read-only memory. The compiler can put the string defined in the Python code in Flash. 
As with freezing the module, you must have a copy of the source code tree on the PC and then use the toolchain to build the firmware. Even if the module has not been fully debugged, the program will still work as long as it can be imported and run.

After importing the module, execute:

.. code::

    micropython.qstr_info(1)

Then copy and paste all Q(xxx) lines into a text editor. Check and delete obviously invalid lines. Open the equivalent directory of the architecture that will be in stmhal (or in use)
file qstrdefsport.h。Copy and paste the corrected line to the end of the file. Save the file, rebuild and flash the firmware. You can check the result by importing the module and sending it again:

.. code::

    micropython.qstr_info(1)

Q(xxx) Line should disappear.

.. _heap:

Heap
--------

当正在运行的程序实例化对象时，将从一个固定大小的池中分配必要的RAM，这个池被称为堆。当对象超出范围
（换言之：已不可用于代码）时，冗余对象即为"垃圾"。"垃圾回收"（GC）的进程回收该内存，并将其返回到空闲堆。
这个过程自动进行，但可通过发出 `gc.collect()` 来直接调用。

有关这方面的讨论有所涉及。为"快速修复"，定期发布以下内容:

.. code::

    gc.collect()
    gc.threshold(gc.mem_free() // 4 + gc.mem_alloc())

碎片化
~~~~~~~~~~~~~

程序创建对象 ``foo`` ，然后创建对象 ``bar`` 。随后 ``foo`` 超出范围，但 ``bar`` 仍保留。 ``foo`` 所占用的
RAM将被GC回收。但是，若 ``bar`` 被分配到更高地址，从 ``foo`` 回收的RAM只能用于不大于 ``foo`` 的对象。
在复杂或长时间运行的程序中，堆可进行碎片化处理：尽管存在大量可用的RAM，但并无足够的连续空间来分配特定对象，且程序因存储器错误而失效。

上述技术旨在最大限度地减少这种情况。 在需要大的永久性缓冲区或其他对象的情况下，最好在程序执行过程中、
碎片化进行前尽早将这些缓冲区实例化。 可通过监视堆的状态和控制GC来进一步改进。概述如下。

报告
~~~~~~~~~

许多库函数可用于报告内存分配和控制GC。这些都可以在 `gc` 和 `micropython` 模块中找到。
下面的例子可能被粘贴在REPL（ctrl e进入粘贴模式，ctrl d运行它）。许多库函数可用于报告内存分配并控制GC。
这些同样存在 `gc` 和 `micropython` 模块中。以下示例可能粘贴到REPL中（ ``ctrl e`` 进入粘贴模式， ``ctrl d`` 运行它）。

.. code::

    import gc
    import micropython
    gc.collect()
    micropython.mem_info()
    print('-----------------------------')
    print('Initial free: {} allocated: {}'.format(gc.mem_free(), gc.mem_alloc()))
    def func():
        a = bytearray(10000)
    gc.collect()
    print('Func definition: {} allocated: {}'.format(gc.mem_free(), gc.mem_alloc()))
    func()
    print('Func run free: {} allocated: {}'.format(gc.mem_free(), gc.mem_alloc()))
    gc.collect()
    print('Garbage collect free: {} allocated: {}'.format(gc.mem_free(), gc.mem_alloc()))
    print('-----------------------------')
    micropython.mem_info(1)

以上使用的方法:

* `gc.collect()` 强制执行垃圾收集。见脚注。
* `micropython.mem_info()` 打印RAM利用率的总结。
* `gc.mem_free()` 返回空闲堆大小（以字节为单位）。
* `gc.mem_alloc()` 返回当前分配的字节数量。
* ``micropython.mem_info(1)`` 打印堆利用率的表格（详情见下）。

生成的数字取决于平台，但可以看到，定义函数使用由编译器发出的字节码形式的少量RAM（编译器使用的RAM已被回收）。
运行该函数使用超过10KiB，但返回时， ``a`` 为垃圾，因为它超出范围且无法引用。最后的 `gc.collect()` 会恢复内存。

由 ``micropython.mem_info(1)`` 生成的最终输出将有所不同，但可能会如下解释:

====== =================
 符号    含义
   .   空闲块
   h   head block
   =   tail block
   m   marked head block
   T   元组
   L   列表
   D   字典
   F   浮点数
   B   字节代码
   M   模块
====== =================

每个字母代表一个内存块，每个块16字节。因此，堆转储的一行代表0x400字节或1KiB的RAM。

控制垃圾回收
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

可随时通过发出 `gc.collect()` 来请求GC。定期执行首先有助于防止碎片化，其次也有利于提高性能。
GC可能耗费数毫秒，在工作量较小时耗时更短（在Pyboard上只需大约1ms）。显式调用可最大限度减少延迟，
同时确保其在程序中可接受的情况下出现。

以下情况下，自动GC将被激活。尝试分配失败时，执行GC并重新尝试分配。只有在此分配失败时才会引发异常。
其次，若可用RAM数量低于阈值，则会触发自动GC。这个阈值可随执行进行而调整:

.. code::

    gc.collect()
    gc.threshold(gc.mem_free() // 4 + gc.mem_alloc())

超过25％的当前空闲堆被占用时，将触发GC。

通常，模块应在运行时使用构造函数或其他初始化函数实例化数据对象。这一因为，若在初始化时发生这种情况，
则在导入后续模块时，编译器可能会缺乏可用RAM。若模块在导入时实例化数据，那么在导入后发出的 `gc.collect()` 会改善这一问题。

字符串操作
-----------------

MicroPython以有效的方式处理字符串，理解其处理方式这可帮助设计在微控制器上运行的应用程序。
模块被编译时，出现多次的字符串只存储一次，此过程被称为字符串驻留。在MicroPython中，
驻留字符串被称为 ``qstr`` 。在正常导入的模块中，单个实例将位于RAM中，但如上所述，在冻结为字节码的模块中，则将位于Flash中。

字符串对比也使用散列有效进行（而非逐个字符执行）。因此，在性能和RAM使用方面，使用字符串而非整数的惩罚可能会很小-这可能会让C程序员感到意外。

附言
----------

MicroPython传输、返回并（默认为）通过引用复制对象。一个引用占用一个机器字，所以这些进程在RAM使用率和速度方面较为高效。

在必需变量（其大小既非一个字节也非一个机器字）的情况下，将有可帮助有效存储变量并进行转换的标准库。
见 `array` 、 `ustruct` 和 `uctypes` 模块。

脚注：gc.collect()返回值
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

在Unix和Windows平台上， `gc.collect()` 方法返回一个整数，该整数表示在回收中收回的不同内存
区域的数量（更确切地说，是变为空闲块的head block的数量）。出于效率原因，baremetal端口不返回此值。
